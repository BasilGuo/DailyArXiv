---
title: Latest 15 Papers - March 21, 2024
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Time Series
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[An Analysis of Linear Time Series Forecasting Models](http://arxiv.org/abs/2403.14587v1)** | 2024-03-21 | <details><summary>Show</summary><p>Despite their simplicity, linear models perform well at time series forecasting, even when pitted against deeper and more expensive models. A number of variations to the linear model have been proposed, often including some form of feature normalisation that improves model generalisation. In this paper we analyse the sets of functions expressible using these linear model architectures. In so doing we show that several popular variants of linear models for time series forecasting are equivalent and functionally indistinguishable from standard, unconstrained linear regression. We characterise the model classes for each linear variant. We demonstrate that each model can be reinterpreted as unconstrained linear regression over a suitably augmented feature set, and therefore admit closed-form solutions when using a mean-squared loss function. We provide experimental evidence that the models under inspection learn nearly identical solutions, and finally demonstrate that the simpler closed form solutions are superior forecasters across 72% of test settings.</p></details> |  |
| **[Estimating Physical Information Consistency of Channel Data Augmentation   for Remote Sensing Images](http://arxiv.org/abs/2403.14547v1)** | 2024-03-21 | <details><summary>Show</summary><p>The application of data augmentation for deep learning (DL) methods plays an important role in achieving state-of-the-art results in supervised, semi-supervised, and self-supervised image classification. In particular, channel transformations (e.g., solarize, grayscale, brightness adjustments) are integrated into data augmentation pipelines for remote sensing (RS) image classification tasks. However, contradicting beliefs exist about their proper applications to RS images. A common point of critique is that the application of channel augmentation techniques may lead to physically inconsistent spectral data (i.e., pixel signatures). To shed light on the open debate, we propose an approach to estimate whether a channel augmentation technique affects the physical information of RS images. To this end, the proposed approach estimates a score that measures the alignment of a pixel signature within a time series that can be naturally subject to deviations caused by factors such as acquisition conditions or phenological states of vegetation. We compare the scores associated with original and augmented pixel signatures to evaluate the physical consistency. Experimental results on a multi-label image classification task show that channel augmentations yielding a score that exceeds the expected deviation of original pixel signatures can not improve the performance of a baseline model trained without augmentation.</p></details> | <details><summary>Accep...</summary><p>Accepted at the IEEE International Geoscience and Remote Sensing   Symposium</p></details> |
| **[Let's do the time-warp-attend: Learning topological invariants of   dynamical systems](http://arxiv.org/abs/2312.09234v3)** | 2024-03-21 | <details><summary>Show</summary><p>Dynamical systems across the sciences, from electrical circuits to ecological networks, undergo qualitative and often catastrophic changes in behavior, called bifurcations, when their underlying parameters cross a threshold. Existing methods predict oncoming catastrophes in individual systems but are primarily time-series-based and struggle both to categorize qualitative dynamical regimes across diverse systems and to generalize to real data. To address this challenge, we propose a data-driven, physically-informed deep-learning framework for classifying dynamical regimes and characterizing bifurcation boundaries based on the extraction of topologically invariant features. We focus on the paradigmatic case of the supercritical Hopf bifurcation, which is used to model periodic dynamics across a wide range of applications. Our convolutional attention method is trained with data augmentations that encourage the learning of topological invariants which can be used to detect bifurcation boundaries in unseen systems and to design models of biological systems like oscillatory gene regulatory networks. We further demonstrate our method's use in analyzing real data by recovering distinct proliferation and differentiation dynamics along pancreatic endocrinogenesis trajectory in gene expression space based on single-cell data. Our method provides valuable insights into the qualitative, long-term behavior of a wide range of dynamical systems, and can detect bifurcations or catastrophic transitions in large-scale physical and biological systems.</p></details> |  |
| **[Phenology curve estimation via a mixed model representation of   functional principal components: Characterizing time series of   satellite-derived vegetation indices](http://arxiv.org/abs/2403.14451v1)** | 2024-03-21 | <details><summary>Show</summary><p>Vegetation phenology consists of studying synchronous stationary events, such as the vegetation green up and leaves senescence, that can be construed as adaptive responses to climatic constraints. In this paper, we propose a method to estimate the annual phenology curve from multi-annual observations of time series of vegetation indices derived from satellite images. We fitted the classical harmonic regression model to annual-based time series in order to construe the original data set as realizations of a functional process. Hierarchical clustering was applied to define a nearly homogeneous group of annual (smoothed) time series from which a representative and idealized phenology curve was estimated at the pixel level. This curve resulted from fitting a mixed model, based on functional principal components, to the homogeneous group of time series. Leveraging the idealized phenology curve, we employed standard calculus criteria to estimate the following phenological parameters (stationary events): green up, start of season, maturity, senescence, end of season and dormancy. By applying the proposed methodology to four different data cubes (time series from 2000 to 2023 of a popular satellite-derived vegetation index) recorded across grasslands, forests, and annual rainfed agricultural zones of a Flora and Fauna Protected Area in northern Mexico, we verified that our approach characterizes properly the phenological cycle in vegetation with nearly periodic dynamics, such as grasslands and agricultural areas. The R package sephora was used for all computations in this paper.</p></details> | <details><summary>18 pa...</summary><p>18 pages, 3 figures, 6 tables</p></details> |
| **[HySim: An Efficient Hybrid Similarity Measure for Patch Matching in   Image Inpainting](http://arxiv.org/abs/2403.14292v1)** | 2024-03-21 | <details><summary>Show</summary><p>Inpainting, for filling missing image regions, is a crucial task in various applications, such as medical imaging and remote sensing. Trending data-driven approaches efficiency, for image inpainting, often requires extensive data preprocessing. In this sense, there is still a need for model-driven approaches in case of application constrained with data availability and quality, especially for those related for time series forecasting using image inpainting techniques. This paper proposes an improved modeldriven approach relying on patch-based techniques. Our approach deviates from the standard Sum of Squared Differences (SSD) similarity measure by introducing a Hybrid Similarity (HySim), which combines both strengths of Chebychev and Minkowski distances. This hybridization enhances patch selection, leading to high-quality inpainting results with reduced mismatch errors. Experimental results proved the effectiveness of our approach against other model-driven techniques, such as diffusion or patch-based approaches, showcasing its effectiveness in achieving visually pleasing restorations.</p></details> |  |
| **[PGCN: Progressive Graph Convolutional Networks for Spatial-Temporal   Traffic Forecasting](http://arxiv.org/abs/2202.08982v3)** | 2024-03-21 | <details><summary>Show</summary><p>The complex spatial-temporal correlations in transportation networks make the traffic forecasting problem challenging. Since transportation system inherently possesses graph structures, many research efforts have been put with graph neural networks. Recently, constructing adaptive graphs to the data has shown promising results over the models relying on a single static graph structure. However, the graph adaptations are applied during the training phases and do not reflect the data used during the testing phases. Such shortcomings can be problematic especially in traffic forecasting since the traffic data often suffer from unexpected changes and irregularities in the time series. In this study, we propose a novel traffic forecasting framework called Progressive Graph Convolutional Network (PGCN). PGCN constructs a set of graphs by progressively adapting to online input data during the training and testing phases. Specifically, we implemented the model to construct progressive adjacency matrices by learning trend similarities among graph nodes. Then, the model is combined with the dilated causal convolution and gated activation unit to extract temporal features. With residual and skip connections, PGCN performs the traffic prediction. When applied to seven real-world traffic datasets of diverse geometric nature, the proposed model achieves state-of-the-art performance with consistency in all datasets. We conclude that the ability of PGCN to progressively adapt to input data enables the model to generalize in different study sites with robustness.</p></details> |
| **[DiffSTOCK: Probabilistic relational Stock Market Predictions using   Diffusion Models](http://arxiv.org/abs/2403.14063v1)** | 2024-03-21 | <details><summary>Show</summary><p>In this work, we propose an approach to generalize denoising diffusion probabilistic models for stock market predictions and portfolio management. Present works have demonstrated the efficacy of modeling interstock relations for market time-series forecasting and utilized Graph-based learning models for value prediction and portfolio management. Though convincing, these deterministic approaches still fall short of handling uncertainties i.e., due to the low signal-to-noise ratio of the financial data, it is quite challenging to learn effective deterministic models. Since the probabilistic methods have shown to effectively emulate higher uncertainties for time-series predictions. To this end, we showcase effective utilisation of Denoising Diffusion Probabilistic Models (DDPM), to develop an architecture for providing better market predictions conditioned on the historical financial indicators and inter-stock relations. Additionally, we also provide a novel deterministic architecture MaTCHS which uses Masked Relational Transformer(MRT) to exploit inter-stock relations along with historical stock features. We demonstrate that our model achieves SOTA performance for movement predication and Portfolio management.</p></details> | <details><summary>Accep...</summary><p>Accepted for presentation to the 2024 IEEE International Conference   on Acoustics, Speech, and Signal Processing (ICASSP 2024), Seoul, Korea</p></details> |
| **[Modality-aware Transformer for Financial Time series Forecasting](http://arxiv.org/abs/2310.01232v2)** | 2024-03-20 | <details><summary>Show</summary><p>Time series forecasting presents a significant challenge, particularly when its accuracy relies on external data sources rather than solely on historical values. This issue is prevalent in the financial sector, where the future behavior of time series is often intricately linked to information derived from various textual reports and a multitude of economic indicators. In practice, the key challenge lies in constructing a reliable time series forecasting model capable of harnessing data from diverse sources and extracting valuable insights to predict the target time series accurately. In this work, we tackle this challenging problem and introduce a novel multimodal transformer-based model named the \textit{Modality-aware Transformer}. Our model excels in exploring the power of both categorical text and numerical timeseries to forecast the target time series effectively while providing insights through its neural attention mechanism. To achieve this, we develop feature-level attention layers that encourage the model to focus on the most relevant features within each data modality. By incorporating the proposed feature-level attention, we develop a novel Intra-modal multi-head attention (MHA), Inter-modal MHA and Target-modal MHA in a way that both feature and temporal attentions are incorporated in MHAs. This enables the MHAs to generate temporal attentions with consideration of modality and feature importance which leads to more informative embeddings. The proposed modality-aware structure enables the model to effectively exploit information within each modality as well as foster cross-modal understanding. Our extensive experiments on financial datasets demonstrate that Modality-aware Transformer outperforms existing methods, offering a novel and practical solution to the complex challenges of multi-modal financial time series forecasting.</p></details> |  |
| **[Synthetic Data Applications in Finance](http://arxiv.org/abs/2401.00081v2)** | 2024-03-20 | <details><summary>Show</summary><p>Synthetic data has made tremendous strides in various commercial settings including finance, healthcare, and virtual reality. We present a broad overview of prototypical applications of synthetic data in the financial sector and in particular provide richer details for a few select ones. These cover a wide variety of data modalities including tabular, time-series, event-series, and unstructured arising from both markets and retail financial applications. Since finance is a highly regulated industry, synthetic data is a potential approach for dealing with issues related to privacy, fairness, and explainability. Various metrics are utilized in evaluating the quality and effectiveness of our approaches in these applications. We conclude with open directions in synthetic data in the context of the financial domain.</p></details> | <details><summary>50 pa...</summary><p>50 pages, journal submission; updated 6 privacy levels</p></details> |
| **[Sequential Modeling of Complex Marine Navigation: Case Study on a   Passenger Vessel (Student Abstract)](http://arxiv.org/abs/2403.13909v1)** | 2024-03-20 | <details><summary>Show</summary><p>The maritime industry's continuous commitment to sustainability has led to a dedicated exploration of methods to reduce vessel fuel consumption. This paper undertakes this challenge through a machine learning approach, leveraging a real-world dataset spanning two years of a ferry in west coast Canada. Our focus centers on the creation of a time series forecasting model given the dynamic and static states, actions, and disturbances. This model is designed to predict dynamic states based on the actions provided, subsequently serving as an evaluative tool to assess the proficiency of the ferry's operation under the captain's guidance. Additionally, it lays the foundation for future optimization algorithms, providing valuable feedback on decision-making processes. To facilitate future studies, our code is available at \url{https://github.com/pagand/model_optimze_vessel/tree/AAAI}</p></details> | <details><summary>5 pag...</summary><p>5 pages, 3 figures, AAAI 2024 student abstract</p></details> |
| **[Probabilistic Forecasting with Stochastic Interpolants and Föllmer   Processes](http://arxiv.org/abs/2403.13724v1)** | 2024-03-20 | <details><summary>Show</summary><p>We propose a framework for probabilistic forecasting of dynamical systems based on generative modeling. Given observations of the system state over time, we formulate the forecasting problem as sampling from the conditional distribution of the future system state given its current state. To this end, we leverage the framework of stochastic interpolants, which facilitates the construction of a generative model between an arbitrary base distribution and the target. We design a fictitious, non-physical stochastic dynamics that takes as initial condition the current system state and produces as output a sample from the target conditional distribution in finite time and without bias. This process therefore maps a point mass centered at the current state onto a probabilistic ensemble of forecasts. We prove that the drift coefficient entering the stochastic differential equation (SDE) achieving this task is non-singular, and that it can be learned efficiently by square loss regression over the time-series data. We show that the drift and the diffusion coefficients of this SDE can be adjusted after training, and that a specific choice that minimizes the impact of the estimation error gives a F\"ollmer process. We highlight the utility of our approach on several complex, high-dimensional forecasting problems, including stochastically forced Navier-Stokes and video prediction on the KTH and CLEVRER datasets.</p></details> |  |
| **[Adaptive estimation for Weakly Dependent Functional Times Series](http://arxiv.org/abs/2403.13706v1)** | 2024-03-20 | <details><summary>Show</summary><p>The local regularity of functional time series is studied under $L^p-m-$appro\-ximability assumptions. The sample paths are observed with error at possibly random design points. Non-asymptotic concentration bounds of the regularity estimators are derived. As an application, we build nonparametric mean and autocovariance functions estimators that adapt to the regularity and the design, which can be sparse or dense. We also derive the asymptotic normality of the mean estimator, which allows honest inference for irregular mean functions. Simulations and a real data application illustrate the performance of the new estimators.</p></details> |  |
| **[Data Augmentation for Time-Series Classification: An Extensive Empirical   Study and Comprehensive Survey](http://arxiv.org/abs/2310.10060v3)** | 2024-03-20 | <details><summary>Show</summary><p>Data Augmentation (DA) has emerged as an indispensable strategy in Time Series Classification (TSC), primarily due to its capacity to amplify training samples, thereby bolstering model robustness, diversifying datasets, and curtailing overfitting. However, the current landscape of DA in TSC is plagued with fragmented literature reviews, nebulous methodological taxonomies, inadequate evaluative measures, and a dearth of accessible, user-oriented tools. In light of these challenges, this study embarks on an exhaustive dissection of DA methodologies within the TSC realm. Our initial approach involved an extensive literature review spanning a decade, revealing that contemporary surveys scarcely capture the breadth of advancements in DA for TSC, prompting us to meticulously analyze over 100 scholarly articles to distill more than 60 unique DA techniques. This rigorous analysis precipitated the formulation of a novel taxonomy, purpose-built for the intricacies of DA in TSC, categorizing techniques into five principal echelons: Transformation-Based, Pattern-Based, Generative, Decomposition-Based, and Automated Data Augmentation. Our taxonomy promises to serve as a robust navigational aid for scholars, offering clarity and direction in method selection. Addressing the conspicuous absence of holistic evaluations for prevalent DA techniques, we executed an all-encompassing empirical assessment, wherein upwards of 15 DA strategies were subjected to scrutiny across 8 UCR time-series datasets, employing ResNet and a multi-faceted evaluation paradigm encompassing Accuracy, Method Ranking, and Residual Analysis, yielding a benchmark accuracy of 88.94 +- 11.83%. Our investigation underscored the inconsistent efficacies of DA techniques, with...</p></details> |  |
| **[Capsule Neural Networks as Noise Stabilizer for Time Series Data](http://arxiv.org/abs/2403.13867v1)** | 2024-03-20 | <details><summary>Show</summary><p>Capsule Neural Networks utilize capsules, which bind neurons into a single vector and learn position equivariant features, which makes them more robust than original Convolutional Neural Networks. CapsNets employ an affine transformation matrix and dynamic routing with coupling coefficients to learn robustly. In this paper, we investigate the effectiveness of CapsNets in analyzing highly sensitive and noisy time series sensor data. To demonstrate CapsNets robustness, we compare their performance with original CNNs on electrocardiogram data, a medical time series sensor data with complex patterns and noise. Our study provides empirical evidence that CapsNets function as noise stabilizers, as investigated by manual and adversarial attack experiments using the fast gradient sign method and three manual attacks, including offset shifting, gradual drift, and temporal lagging. In summary, CapsNets outperform CNNs in both manual and adversarial attacked data. Our findings suggest that CapsNets can be effectively applied to various sensor systems to improve their resilience to noise attacks. These results have significant implications for designing and implementing robust machine learning models in real world applications. Additionally, this study contributes to the effectiveness of CapsNet models in handling noisy data and highlights their potential for addressing the challenges of noise data in time series analysis.</p></details> |
| **[Machine learning approach to detect dynamical states from recurrence   measures](http://arxiv.org/abs/2401.10298v2)** | 2024-03-20 | <details><summary>Show</summary><p>We integrate machine learning approaches with nonlinear time series analysis, specifically utilizing recurrence measures to classify various dynamical states emerging from time series. We implement three machine learning algorithms Logistic Regression, Random Forest, and Support Vector Machine for this study. The input features are derived from the recurrence quantification of nonlinear time series and characteristic measures of the corresponding recurrence networks. For training and testing we generate synthetic data from standard nonlinear dynamical systems and evaluate the efficiency and performance of the machine learning algorithms in classifying time series into periodic, chaotic, hyper-chaotic, or noisy categories. Additionally, we explore the significance of input features in the classification scheme and find that the features quantifying the density of recurrence points are the most relevant. Furthermore, we illustrate how the trained algorithms can successfully predict the dynamical states of two variable stars, SX Her and AC Her from the data of their light curves.</p></details> |  |

